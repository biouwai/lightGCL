# 嵌入维度

## 1.解释

- Embedding（嵌入），即将高维的数据或对象映射到低维的向量空间中的过程。这种映射通常用于表示和处理数据，使得数据在新的向量空间中能够更好地捕捉其内在的语义或结构特征。Embedding 技术的核心在于，通过大量数据的训练，模型能够学习到数据之间的复杂关系和深层次特征，并将其转化为计算机易于处理的数值形式。

- 嵌入维度决定模型能够学习到的特征表示的丰富程度。若嵌入维度设置过小，模型难以捕捉到非编码 RNA 和药物耐药性之间复杂的关联信息，可能导致欠拟合，使模型预测性能不佳。若维度设置过大，虽然能学习到更丰富的特征，但会增加模型的复杂度和计算量，还可能引发过拟合问题，降低模型的泛化能力。

## 2.讨论其对模型的影响

实验结果表明：

- 当嵌入维度较小时（32），由于维度较低，可能无法充分捕捉到数据中的复杂信息，导致 AUC 和 AUPR 指标相对较低。
- 当嵌入维度为 64 时，模型达到了最佳性能，AUC 和 AUPR 分别为 0.907 和 0.919。在捕捉数据特征和避免过拟合之间取得了良好的平衡。

- 随着嵌入维度再增加，从 64 增加到 128、256 甚至 512，模型的性能并没有持续提升，AUC 和 AUPR 指标开始出现下降的趋势，这可能是由于过拟合现象的出现。较高的嵌入维度会使模型具有更强的表达能力，但同时也增加了模型的复杂度，使得模型更容易学习到训练数据中的噪声和局部特征，而忽略了数据的整体分布和一般规律，从而在测试集上的表现不佳。

- 当嵌入维度增加到 512 时，AUC 和 AUPR 指标有一定程度的回升。这可能是因为在这个较高的维度下，模型能够捕捉到更多的数据特征，尽管存在过拟合的风险，但由于数据本身的特性，部分新增的特征信息对模型性能有一定的积极影响。然而，从整体趋势来看，过高的嵌入维度并没有带来持续的性能提升。

- 此外，嵌入维度对模型达到最佳性能所需的训练轮数也有影响。随着嵌入维度的增加，模型达到最大 AUC 和 AUPR 所需的训练轮数总体上呈现出减少的趋势。这可能是因为较高的嵌入维度使得模型在训练初期能够更快地收敛，但同时也更容易陷入局部最优解。

# GNN 层数

## 1.解释

- GNN 中的图卷积层数决定了模型对图结构的感知能力和特征的复杂度。较浅的图卷积层数可能更适用于简单的图结构和浅层特征学习，而较深的图卷积层数可以更好地捕捉更复杂的图结构和更深层次的特征表示。选择合适的图卷积层数通常需要根据任务的复杂性和图结构的深度来调整。

- GNN 层数少，信息传播局限于节点直接邻居，模型只能捕捉局部简单关系，对特征抽象程度低，易欠拟合，无法充分挖掘图结构信息。增加层数，节点能聚合更多邻居信息，利于捕捉全局复杂特征和高级抽象特征，提升预测准确性。但层数过多会引发过平滑问题，使节点特征趋同，降低区分度，损害模型性能。因此，需实验调参，找到合适层数，平衡信息挖掘与过平滑问题。

## 2.讨论

- 当 GNN 层数较少，如仅为 1 层时，模型的性能相对较差。单层的 GNN 只能进行一轮的节点特征聚合，其对图结构信息的挖掘能力有限，无法充分学习到节点之间复杂的高阶关系。因此，模型难以准确地对数据进行分类，导致 AUC 和 AUPR 指标较低。

- 当 GNN 层数为 2 时，模型取得了最佳的性能，AUC 达到了 0.909968767706361，AUPR 达到了 0.9196433661101。表明在这个特定的层数设置下，模型能够更有效地捕捉图数据中的结构信息和节点间的关系，从而在分类任务中表现出较高的准确性和稳定性。

- 随着 GNN 层数的增加，模型的性能并非持续提升。当层数增加到 3 层时，AUC 和 AUPR 指标开始出现下降的趋势。这可能是由于过平滑（over - smoothing）现象的出现。随着层数的增多，节点在多次聚合过程中，其特征逐渐趋于相似，丢失了节点的个性信息，使得模型无法区分不同的节点，从而影响了分类性能。

# SVD

## 1. 定义

若 svd_q 较小，降维程度高，计算量大幅降低，模型训练速度加快。但会丢失大量信息，导致模型无法捕捉非编码 RNA 和药物之间复杂的潜在关系，出现欠拟合，降低预测准确性。
当 svd_q 较大，能保留更多信息，模型可学习到更细致的关联特征，提高预测性能。不过，这会增加计算复杂度和内存开销，训练时间变长，还可能引入噪声，引发过拟合

## 2. 讨论

实验结果显示 svd_q 对 AUC 和 AUPR 影响显著。svd_q = 15 时，AUC 达 0.905；svd_q = 10 时，AUPR 为 0.911，表明不同取值下模型在不同指标上各有优势。
svd_q 较小时（如 svd_q = 1），模型性能一般。因其保留奇异值少，捕捉数据重要特征和结构信息有限，限制模型挖掘数据内在规律，致使 AUC 和 AUPR 不高。
随着 svd_q 增大，模型性能先升后波动。svd_q = 10 时，AUC 和 AUPR 明显提升，表明模型能利用更多奇异值信息捕捉复杂特征与全局结构。然而 svd_q 增至 15 和 20 时，AUPR 出现波动甚至下降，可能是引入噪声和冗余信息，影响模型泛化能力。

# dropout

## 1.定义

- 对于任何的一个机器学习任务来说，数据是关键，如果面临数据少且模型复杂的情况，就会导致一个致命的问题是过拟合，过拟合具体表现在：模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。所以过拟合的模型是没有办法应用的。

- 在 2012 年，Hinton 在其论文《Improving neural networks by preventing co-adaptation of feature detectors》中提出 Dropout。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器的共同作用来提高神经网络的性能。

- Dropout 的核心思想是在神经网络的训练过程中，以一定的概率随机 “丢弃”（将神经元的输出值设置为 0）神经网络中的一些神经元。这样做的目的是减少神经元之间的相互依赖，避免过拟合。

## 2.讨论

实验表明，Dropout 比率对模型性能影响显著且复杂。Dropout 比率为 0.2 时，AUC 达 0.9025303685687041；比率为 0.0 时，AUPR 为 0.9178409597413081，显示不同比率在不同指标上各有优势。

比率为 0.0 即不使用 Dropout 时，模型易过拟合。它过度依赖训练数据特定特征与噪声，虽 AUPR 较高，但 AUC 较低，区分正负样本能力受限。

随着比率增加，模型性能先升后降。比率增至 0.2 时，AUC 提升，适当的 Dropout 随机丢弃部分神经元，增强模型泛化能力，使其学习更具鲁棒性的特征表示，提高分类准确性。

当比率升至 0.25、0.3 和 0.5 时，性能下降。AUC 和 AUPR 均明显下降，说明过高比率使模型丢失过多有用信息，限制其表达能力。

# lambda_1

## 1.定义

超参数 lambda_1 用于平衡对比学习损失在总损失函数中的权重。通过实验探究不同 lambda_1 值（从 0 到 0.01 按不同数量级变化）对模型 AUC 和 AUPR 指标的影响。

## 2.

实验结果表明，lambda_1 对 AUC 和 AUPR 影响显著且复杂。lambda_1= 1e - 07 时，AUC 达 0.9081307610453146；lambda_1= 1e - 08 时，AUPR 为 0.9115689766880519，说明不同 lambda_1 值在不同指标上各有优势。

lambda_1= 0 时，总损失函数不考虑对比学习损失，模型仅依赖其他损失项训练，缺乏对样本对比信息的学习，难以有效区分正负样本，性能受限。

lambda_1 增大，模型性能波动变化。取值适中（如 1e - 07）时，对比学习损失比重合适，模型能兼顾样本固有特征与对比信息，提升分类性能和 AUC 指标。

lambda_1 过大（如 0.01），对比学习损失占比过高，模型过度关注样本对比关系，忽略其他重要特征，出现过拟合，AUC 和 AUPR 指标下降。

# lambda2

## 1.定义

正则化是深度学习防过拟合、提泛化能力的重要手段，lambda_2 作为正则化系数，调节正则化损失在总损失中的占比。以下基于不同 lambda_2 值的实验结果，探讨其对模型性能的影响。

### 1. 整体性能趋势

lambda_2 对模型 AUC 和 AUPR 指标呈非单调影响。lambda_2= 1e - 05 时，AUC 达 0.9025，AUPR 为 0.913，综合性能最佳，表明此时正则化损失与其他损失达理想平衡，能有效避免过拟合。

lambda_2 过小甚至为 0 时，正则化作用削弱。以 lambda_2= 0 为例，AUC 为 0.898，AUPR 为 0.910，非最优。缺乏正则化约束，模型易过拟合，泛化能力下降。

lambda_2= 0.01 时，AUC 和 AUPR 显著下降，分别为 0.882 和 0.896。过大的 lambda_2 使正则化损失主导总损失，过度约束参数，限制模型表达能力，致性能下滑。

# 温度参数 temp

## 1.定义

当值较小时，Softmax 函数输出的概率分布会更加尖锐，意味着模型对某一类别的预测更加确定，概率值会集中在得分最高的类别上；当值较大时，概率分布会更加平滑，各个类别的概率值差异减小，模型的预测结果更加 “模糊”，不确定性增加。

## 2. 讨论

temp = 0.3 时，AUC 和 AUPR 表现不错但不如 temp=0.5 时。小 temp 使相似度得分分布尖锐，模型对样本差异更敏感，利于区分正负样本。但过小则可能使模型过度关注局部特征，影响泛化能力。

temp 对 AUC 和 AUPR 影响显著且非单调。temp = 0.5 时，模型综合性能最佳，AUC 达 0.9059196252124764，AUPR 达 0.9215959594588296，表明此参数下模型学习样本异同更有效，分类准确稳定。

temp 增大，模型性能下降。temp = 1 时，AUC 和 AUPR 低于 temp = 0.5；增至 3 和 10 时，虽有波动但整体仍差。大 temp 使相似度得分分布平滑，模型对样本差异敏感度降低，难以区分正负样本，还可能陷入局部最优，无法充分学习有效信息。
